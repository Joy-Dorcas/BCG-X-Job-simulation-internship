{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "---\n",
    "\n",
    "1. Import packages\n",
    "2. Load data\n",
    "3. Feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:31:21.376537Z",
     "start_time": "2025-05-12T16:31:21.373979Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:31:21.473280Z",
     "start_time": "2025-05-12T16:31:21.385539Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./clean_data_after_eda.csv')\n",
    "df[\"date_activ\"] = pd.to_datetime(df[\"date_activ\"], format='%Y-%m-%d')\n",
    "df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format='%Y-%m-%d')\n",
    "df[\"date_modif_prod\"] = pd.to_datetime(df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
    "df[\"date_renewal\"] = pd.to_datetime(df[\"date_renewal\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:31:21.794435Z",
     "start_time": "2025-05-12T16:31:21.783133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>channel_sales</th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>date_activ</th>\n",
       "      <th>date_end</th>\n",
       "      <th>date_modif_prod</th>\n",
       "      <th>date_renewal</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>...</th>\n",
       "      <th>var_6m_price_off_peak_var</th>\n",
       "      <th>var_6m_price_peak_var</th>\n",
       "      <th>var_6m_price_mid_peak_var</th>\n",
       "      <th>var_6m_price_off_peak_fix</th>\n",
       "      <th>var_6m_price_peak_fix</th>\n",
       "      <th>var_6m_price_mid_peak_fix</th>\n",
       "      <th>var_6m_price_off_peak</th>\n",
       "      <th>var_6m_price_peak</th>\n",
       "      <th>var_6m_price_mid_peak</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24011ae4ebbe3035111d65fa7c15bc57</td>\n",
       "      <td>foosdfpfkusacimwkcsosbicdxkicaua</td>\n",
       "      <td>0</td>\n",
       "      <td>54946</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>4.100838e-05</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>2.086294</td>\n",
       "      <td>99.530517</td>\n",
       "      <td>44.235794</td>\n",
       "      <td>2.086425</td>\n",
       "      <td>9.953056e+01</td>\n",
       "      <td>44.236702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d29c2c54acc38ff3c0614d0a653813dd</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-08-21</td>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>2009-08-21</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>189.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.217891e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>1.217891e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>764c75f661154dac3a6c254cd082ea7d</td>\n",
       "      <td>foosdfpfkusacimwkcsosbicdxkicaua</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>47.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.450150e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.450150e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                     channel_sales  \\\n",
       "0  24011ae4ebbe3035111d65fa7c15bc57  foosdfpfkusacimwkcsosbicdxkicaua   \n",
       "1  d29c2c54acc38ff3c0614d0a653813dd                           MISSING   \n",
       "2  764c75f661154dac3a6c254cd082ea7d  foosdfpfkusacimwkcsosbicdxkicaua   \n",
       "\n",
       "   cons_12m  cons_gas_12m  cons_last_month date_activ   date_end  \\\n",
       "0         0         54946                0 2013-06-15 2016-06-15   \n",
       "1      4660             0                0 2009-08-21 2016-08-30   \n",
       "2       544             0                0 2010-04-16 2016-04-16   \n",
       "\n",
       "  date_modif_prod date_renewal  forecast_cons_12m  ...  \\\n",
       "0      2015-11-01   2015-06-23               0.00  ...   \n",
       "1      2009-08-21   2015-08-31             189.95  ...   \n",
       "2      2010-04-16   2015-04-17              47.96  ...   \n",
       "\n",
       "   var_6m_price_off_peak_var  var_6m_price_peak_var  \\\n",
       "0                   0.000131           4.100838e-05   \n",
       "1                   0.000003           1.217891e-03   \n",
       "2                   0.000004           9.450150e-08   \n",
       "\n",
       "   var_6m_price_mid_peak_var  var_6m_price_off_peak_fix  \\\n",
       "0                   0.000908                   2.086294   \n",
       "1                   0.000000                   0.009482   \n",
       "2                   0.000000                   0.000000   \n",
       "\n",
       "   var_6m_price_peak_fix  var_6m_price_mid_peak_fix var_6m_price_off_peak  \\\n",
       "0              99.530517                  44.235794              2.086425   \n",
       "1               0.000000                   0.000000              0.009485   \n",
       "2               0.000000                   0.000000              0.000004   \n",
       "\n",
       "   var_6m_price_peak  var_6m_price_mid_peak  churn  \n",
       "0       9.953056e+01              44.236702      1  \n",
       "1       1.217891e-03               0.000000      0  \n",
       "2       9.450150e-08               0.000000      0  \n",
       "\n",
       "[3 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Feature engineering\n",
    "\n",
    "### Difference between off-peak prices in December and preceding January\n",
    "\n",
    "Below is the code created by your colleague to calculate the feature described above. Use this code to re-create this feature and then think about ways to build on this feature to create features with a higher predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:32:04.670758Z",
     "start_time": "2025-05-12T16:32:04.558764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_date</th>\n",
       "      <th>price_off_peak_var</th>\n",
       "      <th>price_peak_var</th>\n",
       "      <th>price_mid_peak_var</th>\n",
       "      <th>price_off_peak_fix</th>\n",
       "      <th>price_peak_fix</th>\n",
       "      <th>price_mid_peak_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id price_date  price_off_peak_var  \\\n",
       "0  038af19179925da21a25619c5a24b745 2015-01-01            0.151367   \n",
       "1  038af19179925da21a25619c5a24b745 2015-02-01            0.151367   \n",
       "2  038af19179925da21a25619c5a24b745 2015-03-01            0.151367   \n",
       "3  038af19179925da21a25619c5a24b745 2015-04-01            0.149626   \n",
       "4  038af19179925da21a25619c5a24b745 2015-05-01            0.149626   \n",
       "\n",
       "   price_peak_var  price_mid_peak_var  price_off_peak_fix  price_peak_fix  \\\n",
       "0             0.0                 0.0           44.266931             0.0   \n",
       "1             0.0                 0.0           44.266931             0.0   \n",
       "2             0.0                 0.0           44.266931             0.0   \n",
       "3             0.0                 0.0           44.266931             0.0   \n",
       "4             0.0                 0.0           44.266931             0.0   \n",
       "\n",
       "   price_mid_peak_fix  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df = pd.read_csv('price_data (1).csv')\n",
    "price_df[\"price_date\"] = pd.to_datetime(price_df[\"price_date\"], format='%Y-%m-%d')\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T17:25:58.057213Z",
     "start_time": "2025-05-12T17:25:57.974746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offpeak_diff_dec_january_energy</th>\n",
       "      <th>offpeak_diff_dec_january_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002203ffbb812588b632b9e628cc38d</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>0.162916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004351ebdd665e6ee664792efc4fd13</td>\n",
       "      <td>-0.004104</td>\n",
       "      <td>0.177779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010bcc39e42b3c2131ed2ce55246e3c</td>\n",
       "      <td>0.050443</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0010ee3855fdea87602a5b7aba8e42de</td>\n",
       "      <td>-0.010018</td>\n",
       "      <td>0.162916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00114d74e963e47177db89bc70108537</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  offpeak_diff_dec_january_energy  \\\n",
       "0  0002203ffbb812588b632b9e628cc38d                        -0.006192   \n",
       "1  0004351ebdd665e6ee664792efc4fd13                        -0.004104   \n",
       "2  0010bcc39e42b3c2131ed2ce55246e3c                         0.050443   \n",
       "3  0010ee3855fdea87602a5b7aba8e42de                        -0.010018   \n",
       "4  00114d74e963e47177db89bc70108537                        -0.003994   \n",
       "\n",
       "   offpeak_diff_dec_january_power  \n",
       "0                        0.162916  \n",
       "1                        0.177779  \n",
       "2                        1.500000  \n",
       "3                        0.162916  \n",
       "4                       -0.000001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group off-peak prices by companies and month\n",
    "monthly_price_by_id = price_df.groupby(['id', 'price_date']).agg({'price_off_peak_var': 'mean', 'price_off_peak_fix': 'mean'}).reset_index()\n",
    "\n",
    "# Get january and december prices\n",
    "jan_prices = monthly_price_by_id.groupby('id').first().reset_index()\n",
    "dec_prices = monthly_price_by_id.groupby('id').last().reset_index()\n",
    "\n",
    "# Calculate the difference\n",
    "diff = pd.merge(dec_prices.rename(columns={'price_off_peak_var': 'dec_1', 'price_off_peak_fix': 'dec_2'}), jan_prices.drop(columns='price_date'), on='id')\n",
    "diff['offpeak_diff_dec_january_energy'] = diff['dec_1'] - diff['price_off_peak_var']\n",
    "diff['offpeak_diff_dec_january_power'] = diff['dec_2'] - diff['price_off_peak_fix']\n",
    "diff = diff[['id', 'offpeak_diff_dec_january_energy','offpeak_diff_dec_january_power']]\n",
    "diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to get creative and to conduct some of your own feature engineering! Have fun with it, explore different ideas and try to create as many as you can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "Client data shape: (14606, 44)\n",
      "Price data shape: (193002, 8)\n",
      "\n",
      "CREATING PRICE-BASED FEATURES\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_5132\\2016977982.py:94: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  price_changes = price_df.groupby('id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created price-based features\n",
      "\n",
      "CREATING CONSUMPTION-BASED FEATURES\n",
      "\n",
      "Created consumption-based features\n",
      "\n",
      "CREATING MARGIN AND PROFITABILITY FEATURES\n",
      "\n",
      "Created margin and profitability features\n",
      "\n",
      "CREATING TEMPORAL FEATURES\n",
      "\n",
      "Created temporal features\n",
      "\n",
      "CREATING CHANNEL AND ORIGIN FEATURES\n",
      "\n",
      "Created channel and origin features\n",
      "\n",
      "CREATING PRODUCT AND SERVICE FEATURES\n",
      "\n",
      "Created product and service features\n",
      "\n",
      "CREATING INTERACTION FEATURES\n",
      "\n",
      "Created interaction features\n",
      "\n",
      "CREATING AGGREGATE FEATURES\n",
      "\n",
      "Created aggregate features\n",
      "\n",
      "MERGING PRICE FEATURES WITH CLIENT DATA\n",
      "\n",
      "Final dataset shape: (14606, 127)\n",
      "\n",
      "HANDLING MISSING VALUES IN NEW FEATURES\n",
      "\n",
      "Missing values handled\n",
      "\n",
      "REMOVING REDUNDANT COLUMNS\n",
      "\n",
      "Final cleaned dataset shape: (14606, 122)\n",
      "\n",
      "SAVING ENGINEERED DATASET\n",
      "\n",
      "Saved to: client_data_engineered.csv\n",
      "\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "\n",
      "Total new features created: 29\n",
      "Feature categories:\n",
      "  - Price-based features: ~30\n",
      "  - Consumption features: 7\n",
      "  - Margin features: 6\n",
      "  - Temporal features: 16\n",
      "  - Channel/Origin features: 6\n",
      "  - Product/Service features: 8\n",
      "  - Interaction features: 7\n",
      "  - Statistical features: 6\n",
      "Total columns in final dataset: 122\n",
      "Total rows: 14606\n",
      "   peak_diff_dec_jan_energy  price_price_off_peak_var_mean  \\\n",
      "0                 -0.017912                       0.124787   \n",
      "1                  0.000000                       0.149609   \n",
      "2                  0.000528                       0.170512   \n",
      "3                  0.000000                       0.151210   \n",
      "4                 -0.002302                       0.124174   \n",
      "\n",
      "   price_price_peak_var_std power_category_encoded  price_price_peak_fix_max  \\\n",
      "0                  0.005126                      3                  24.43733   \n",
      "1                  0.024677                      1                   0.00000   \n",
      "2                  0.000506                      1                   0.00000   \n",
      "3                  0.000000                      1                   0.00000   \n",
      "4                  0.001885                      2                  24.43733   \n",
      "\n",
      "   price_peak_var_range  price_off_peak_fix_range  peak_diff_dec_jan_power  \\\n",
      "0              0.018480                  3.700961               -24.339581   \n",
      "1              0.085483                  0.177780                 0.000000   \n",
      "2              0.001281                  0.177779                 0.000000   \n",
      "3              0.000000                  0.177779                 0.000000   \n",
      "4              0.004169                  0.162916                 0.097749   \n",
      "\n",
      "   price_off_peak_var_range  offpeak_diff_dec_jan_energy  \n",
      "0                  0.028554                     0.020057  \n",
      "1                  0.005334                    -0.003767  \n",
      "2                  0.004670                    -0.004670  \n",
      "3                  0.004547                    -0.004547  \n",
      "4                  0.008161                    -0.006192  \n",
      "\n",
      "FEATURE ENGINEERING COMPLETE!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature Engineering for Client Churn Prediction\n",
    "This script creates comprehensive features based on:\n",
    "1. Price sensitivity and variations\n",
    "2. Consumption patterns and trends\n",
    "3. Contract and temporal features\n",
    "4. Customer behavior metrics\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. IMPORT PACKAGES AND LOAD DATA\n",
    "print(\"\\nLoading data...\")\n",
    "df = pd.read_csv('./clean_data_after_eda.csv')\n",
    "price_df = pd.read_csv('price_data (1).csv')\n",
    "\n",
    "# Convert date columns\n",
    "df[\"date_activ\"] = pd.to_datetime(df[\"date_activ\"], format='%Y-%m-%d')\n",
    "df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format='%Y-%m-%d')\n",
    "df[\"date_modif_prod\"] = pd.to_datetime(df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
    "df[\"date_renewal\"] = pd.to_datetime(df[\"date_renewal\"], format='%Y-%m-%d')\n",
    "price_df[\"price_date\"] = pd.to_datetime(price_df[\"price_date\"], format='%Y-%m-%d')\n",
    "\n",
    "print(f\"Client data shape: {df.shape}\")\n",
    "print(f\"Price data shape: {price_df.shape}\")\n",
    "\n",
    "# 2. PRICE-BASED FEATURES\n",
    "print(\"\\nCREATING PRICE-BASED FEATURES\\n\")\n",
    "\n",
    "monthly_price_by_id = price_df.groupby(['id', 'price_date']).agg({\n",
    "    'price_off_peak_var': 'mean', \n",
    "    'price_off_peak_fix': 'mean',\n",
    "    'price_peak_var': 'mean',\n",
    "    'price_peak_fix': 'mean',\n",
    "    'price_mid_peak_var': 'mean',\n",
    "    'price_mid_peak_fix': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "jan_prices = monthly_price_by_id.groupby('id').first().reset_index()\n",
    "dec_prices = monthly_price_by_id.groupby('id').last().reset_index()\n",
    "\n",
    "diff = pd.merge(\n",
    "    dec_prices.rename(columns={\n",
    "        'price_off_peak_var': 'dec_off_peak_var',\n",
    "        'price_off_peak_fix': 'dec_off_peak_fix',\n",
    "        'price_peak_var': 'dec_peak_var',\n",
    "        'price_peak_fix': 'dec_peak_fix'\n",
    "    }), \n",
    "    jan_prices.drop(columns='price_date'), \n",
    "    on='id'\n",
    ")\n",
    "\n",
    "diff['offpeak_diff_dec_jan_energy'] = diff['dec_off_peak_var'] - diff['price_off_peak_var']\n",
    "diff['offpeak_diff_dec_jan_power'] = diff['dec_off_peak_fix'] - diff['price_off_peak_fix']\n",
    "diff['peak_diff_dec_jan_energy'] = diff['dec_peak_var'] - diff['price_peak_var']\n",
    "diff['peak_diff_dec_jan_power'] = diff['dec_peak_fix'] - diff['price_peak_fix']\n",
    "\n",
    "price_stats = price_df.groupby('id').agg({\n",
    "    'price_off_peak_var': ['mean', 'std', 'min', 'max'],\n",
    "    'price_peak_var': ['mean', 'std', 'min', 'max'],\n",
    "    'price_off_peak_fix': ['mean', 'std', 'min', 'max'],\n",
    "    'price_peak_fix': ['mean', 'std', 'min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "price_stats.columns = ['_'.join(col).strip('_') for col in price_stats.columns.values]\n",
    "price_stats.columns = ['id'] + [f'price_{col}' for col in price_stats.columns[1:]]\n",
    "\n",
    "price_stats['price_off_peak_var_range'] = price_stats['price_price_off_peak_var_max'] - price_stats['price_price_off_peak_var_min']\n",
    "price_stats['price_peak_var_range'] = price_stats['price_price_peak_var_max'] - price_stats['price_price_peak_var_min']\n",
    "price_stats['price_off_peak_fix_range'] = price_stats['price_price_off_peak_fix_max'] - price_stats['price_price_off_peak_fix_min']\n",
    "\n",
    "price_df_sorted = price_df.sort_values(['id', 'price_date'])\n",
    "first_3_months = price_df_sorted.groupby('id').head(3).groupby('id').agg({\n",
    "    'price_off_peak_var': 'mean',\n",
    "    'price_peak_var': 'mean',\n",
    "    'price_off_peak_fix': 'mean'\n",
    "}).reset_index()\n",
    "first_3_months.columns = ['id', 'first3m_off_peak_var', 'first3m_peak_var', 'first3m_off_peak_fix']\n",
    "\n",
    "last_3_months = price_df_sorted.groupby('id').tail(3).groupby('id').agg({\n",
    "    'price_off_peak_var': 'mean',\n",
    "    'price_peak_var': 'mean',\n",
    "    'price_off_peak_fix': 'mean'\n",
    "}).reset_index()\n",
    "last_3_months.columns = ['id', 'last3m_off_peak_var', 'last3m_peak_var', 'last3m_off_peak_fix']\n",
    "\n",
    "price_trend = pd.merge(first_3_months, last_3_months, on='id')\n",
    "price_trend['price_trend_off_peak_var'] = price_trend['last3m_off_peak_var'] - price_trend['first3m_off_peak_var']\n",
    "price_trend['price_trend_peak_var'] = price_trend['last3m_peak_var'] - price_trend['first3m_peak_var']\n",
    "price_trend['price_trend_off_peak_fix'] = price_trend['last3m_off_peak_fix'] - price_trend['first3m_off_peak_fix']\n",
    "\n",
    "price_changes = price_df.groupby('id').apply(\n",
    "    lambda x: (x.sort_values('price_date')['price_off_peak_var'].diff() != 0).sum()\n",
    ").reset_index()\n",
    "price_changes.columns = ['id', 'num_price_changes_off_peak']\n",
    "\n",
    "print(f\"Created price-based features\")\n",
    "\n",
    "# 3. CONSUMPTION-BASED FEATURES\n",
    "print(\"\\nCREATING CONSUMPTION-BASED FEATURES\\n\")\n",
    "\n",
    "df['cons_12m_per_pow_max'] = df['cons_12m'] / (df['pow_max'] + 1)\n",
    "df['cons_gas_ratio'] = df['cons_gas_12m'] / (df['cons_12m'] + 1)\n",
    "df['actual_vs_forecast'] = df['cons_12m'] / (df['forecast_cons_12m'] + 1)\n",
    "df['recent_consumption_ratio'] = df['cons_last_month'] / (df['cons_12m'] / 12 + 1)\n",
    "\n",
    "df['is_low_consumer'] = (df['cons_12m'] < df['cons_12m'].quantile(0.25)).astype(int)\n",
    "df['is_high_consumer'] = (df['cons_12m'] > df['cons_12m'].quantile(0.75)).astype(int)\n",
    "df['has_recent_consumption'] = (df['cons_last_month'] > 0).astype(int)\n",
    "df['total_energy_consumption'] = df['cons_12m'] + df['cons_gas_12m']\n",
    "\n",
    "print(f\"Created consumption-based features\")\n",
    "\n",
    "# 4. MARGIN AND PROFITABILITY FEATURES\n",
    "print(\"\\nCREATING MARGIN AND PROFITABILITY FEATURES\\n\")\n",
    "\n",
    "df['margin_per_kwh'] = df['net_margin'] / (df['cons_12m'] + 1)\n",
    "df['margin_efficiency'] = df['net_margin'] / (df['pow_max'] + 1)\n",
    "\n",
    "df['is_high_margin_client'] = (df['net_margin'] > df['net_margin'].quantile(0.75)).astype(int)\n",
    "df['is_low_margin_client'] = (df['net_margin'] < df['net_margin'].quantile(0.25)).astype(int)\n",
    "\n",
    "df['margin_to_consumption_ratio'] = df['net_margin'] / (df['cons_12m'] + 1)\n",
    "df['gross_to_net_margin_ratio'] = df['margin_gross_pow_ele'] / (df['margin_net_pow_ele'] + 1)\n",
    "\n",
    "print(f\"Created margin and profitability features\")\n",
    "\n",
    "# 5. TEMPORAL/DATE-BASED FEATURES\n",
    "print(\"\\nCREATING TEMPORAL FEATURES\\n\")\n",
    "\n",
    "df['contract_length_days'] = (df['date_end'] - df['date_activ']).dt.days\n",
    "df['contract_length_years'] = df['contract_length_days'] / 365.25\n",
    "df['days_to_end'] = (df['date_end'] - pd.Timestamp('2016-01-01')).dt.days\n",
    "df['months_since_modification'] = ((pd.Timestamp('2016-01-01') - df['date_modif_prod']).dt.days / 30.44).round()\n",
    "df['months_to_renewal'] = ((df['date_renewal'] - pd.Timestamp('2016-01-01')).dt.days / 30.44).round()\n",
    "\n",
    "df['activation_month'] = df['date_activ'].dt.month\n",
    "df['activation_year'] = df['date_activ'].dt.year\n",
    "df['activation_quarter'] = df['date_activ'].dt.quarter\n",
    "df['is_summer_activation'] = df['activation_month'].isin([6, 7, 8]).astype(int)\n",
    "df['is_winter_activation'] = df['activation_month'].isin([12, 1, 2]).astype(int)\n",
    "\n",
    "df['has_modified_contract'] = (df['date_activ'] != df['date_modif_prod']).astype(int)\n",
    "df['modification_to_renewal_days'] = (df['date_renewal'] - df['date_modif_prod']).dt.days\n",
    "\n",
    "df['tenure_category'] = pd.cut(df['num_years_antig'], bins=[0, 3, 5, 8, 15], labels=['new', 'established', 'loyal', 'veteran'])\n",
    "df['is_new_client'] = (df['num_years_antig'] <= 3).astype(int)\n",
    "df['is_loyal_client'] = (df['num_years_antig'] >= 6).astype(int)\n",
    "\n",
    "print(f\"Created temporal features\")\n",
    "\n",
    "# 6. CHANNEL AND ORIGIN FEATURES\n",
    "print(\"\\nCREATING CHANNEL AND ORIGIN FEATURES\\n\")\n",
    "\n",
    "channel_churn_rate = df.groupby('channel_sales')['churn'].mean().to_dict()\n",
    "df['channel_churn_rate'] = df['channel_sales'].map(channel_churn_rate)\n",
    "origin_churn_rate = df.groupby('origin_up')['churn'].mean().to_dict()\n",
    "df['origin_churn_rate'] = df['origin_up'].map(origin_churn_rate)\n",
    "\n",
    "df['is_missing_channel'] = (df['channel_sales'] == 'MISSING').astype(int)\n",
    "df['is_missing_origin'] = (df['origin_up'] == 'MISSING').astype(int)\n",
    "\n",
    "df['is_high_risk_channel'] = (df['channel_churn_rate'] > 0.10).astype(int)\n",
    "df['is_high_risk_origin'] = (df['origin_churn_rate'] > 0.10).astype(int)\n",
    "\n",
    "print(f\"Created channel and origin features\")\n",
    "\n",
    "# 7. PRODUCT AND SERVICE FEATURES\n",
    "print(\"\\nCREATING PRODUCT AND SERVICE FEATURES\\n\")\n",
    "\n",
    "df['has_multiple_products'] = (df['nb_prod_act'] > 1).astype(int)\n",
    "df['product_diversity'] = df['nb_prod_act']\n",
    "\n",
    "df['has_gas_binary'] = (df['has_gas'] == 't').astype(int)\n",
    "df['electricity_only'] = ((df['has_gas'] == 'f') & (df['cons_12m'] > 0)).astype(int)\n",
    "df['gas_only'] = ((df['has_gas'] == 't') & (df['cons_gas_12m'] > 0) & (df['cons_12m'] == 0)).astype(int)\n",
    "df['dual_service'] = ((df['cons_12m'] > 0) & (df['cons_gas_12m'] > 0)).astype(int)\n",
    "\n",
    "df['power_category'] = pd.cut(df['pow_max'], bins=[0, 10, 15, 25, 400], labels=['low', 'medium', 'high', 'very_high'])\n",
    "df['is_high_power_client'] = (df['pow_max'] > df['pow_max'].quantile(0.75)).astype(int)\n",
    "\n",
    "print(f\"Created product and service features\")\n",
    "\n",
    "# 8. INTERACTION FEATURES\n",
    "print(\"\\nCREATING INTERACTION FEATURES\\n\")\n",
    "\n",
    "df['price_sensitivity_score'] = df['margin_per_kwh'] * df['is_low_consumer']\n",
    "df['high_margin_low_consumption'] = ((df['is_high_margin_client'] == 1) & (df['is_low_consumer'] == 1)).astype(int)\n",
    "df['loyal_low_consumer'] = ((df['is_loyal_client'] == 1) & (df['is_low_consumer'] == 1)).astype(int)\n",
    "df['new_high_margin'] = ((df['is_new_client'] == 1) & (df['is_high_margin_client'] == 1)).astype(int)\n",
    "df['risky_channel_low_consumption'] = ((df['is_high_risk_channel'] == 1) & (df['is_low_consumer'] == 1)).astype(int)\n",
    "df['forecast_error_abs'] = abs(df['actual_vs_forecast'] - 1)\n",
    "df['is_forecast_accurate'] = (df['forecast_error_abs'] < 0.2).astype(int)\n",
    "\n",
    "print(f\"Created interaction features\")\n",
    "\n",
    "# 9. AGGREGATE AND STATISTICAL FEATURES\n",
    "print(\"\\nCREATING AGGREGATE FEATURES\\n\")\n",
    "\n",
    "df['cons_12m_zscore'] = stats.zscore(df['cons_12m'])\n",
    "df['net_margin_zscore'] = stats.zscore(df['net_margin'])\n",
    "df['pow_max_zscore'] = stats.zscore(df['pow_max'])\n",
    "df['cons_percentile'] = df['cons_12m'].rank(pct=True)\n",
    "df['margin_percentile'] = df['net_margin'].rank(pct=True)\n",
    "df['tenure_percentile'] = df['num_years_antig'].rank(pct=True)\n",
    "\n",
    "print(f\"Created aggregate features\")\n",
    "\n",
    "# 10. MERGE ALL PRICE FEATURES\n",
    "print(\"\\nMERGING PRICE FEATURES WITH CLIENT DATA\\n\")\n",
    "\n",
    "price_features = diff[['id', 'offpeak_diff_dec_jan_energy', 'offpeak_diff_dec_jan_power', \n",
    "                       'peak_diff_dec_jan_energy', 'peak_diff_dec_jan_power']]\n",
    "price_features = price_features.merge(price_stats, on='id', how='left')\n",
    "price_features = price_features.merge(price_trend[['id', 'price_trend_off_peak_var', \n",
    "                                                    'price_trend_peak_var', 'price_trend_off_peak_fix']], \n",
    "                                      on='id', how='left')\n",
    "price_features = price_features.merge(price_changes, on='id', how='left')\n",
    "\n",
    "df_final = df.merge(price_features, on='id', how='left')\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "\n",
    "# 11. HANDLE MISSING VALUES IN NEW FEATURES\n",
    "print(\"\\nHANDLING MISSING VALUES IN NEW FEATURES\\n\")\n",
    "\n",
    "price_cols = [col for col in df_final.columns if 'price' in col.lower() or 'peak' in col.lower()]\n",
    "for col in price_cols:\n",
    "    if df_final[col].isna().sum() > 0:\n",
    "        df_final[col].fillna(df_final[col].median(), inplace=True)\n",
    "\n",
    "df_final = df_final.replace([np.inf, -np.inf], np.nan)\n",
    "for col in df_final.select_dtypes(include=[np.number]).columns:\n",
    "    if df_final[col].isna().sum() > 0:\n",
    "        df_final[col].fillna(df_final[col].median(), inplace=True)\n",
    "\n",
    "print(\"Missing values handled\")\n",
    "\n",
    "# 12. REMOVE REDUNDANT/USELESS COLUMNS\n",
    "print(\"\\nREMOVING REDUNDANT COLUMNS\\n\")\n",
    "\n",
    "columns_to_drop = ['id', 'date_activ', 'date_end', 'date_modif_prod', 'date_renewal']\n",
    "df_final_clean = df_final.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "if 'tenure_category' in df_final_clean.columns:\n",
    "    tenure_map = {'new': 0, 'established': 1, 'loyal': 2, 'veteran': 3}\n",
    "    df_final_clean['tenure_category_encoded'] = df_final_clean['tenure_category'].map(tenure_map)\n",
    "    df_final_clean = df_final_clean.drop('tenure_category', axis=1)\n",
    "\n",
    "if 'power_category' in df_final_clean.columns:\n",
    "    power_map = {'low': 0, 'medium': 1, 'high': 2, 'very_high': 3}\n",
    "    df_final_clean['power_category_encoded'] = df_final_clean['power_category'].map(power_map)\n",
    "    df_final_clean = df_final_clean.drop('power_category', axis=1)\n",
    "\n",
    "print(f\"Final cleaned dataset shape: {df_final_clean.shape}\")\n",
    "\n",
    "# 13. SAVE ENGINEERED DATASET\n",
    "print(\"\\nSAVING ENGINEERED DATASET\\n\")\n",
    "\n",
    "df_final_clean.to_csv('client_data_engineered.csv', index=False)\n",
    "print(\"Saved to: client_data_engineered.csv\")\n",
    "\n",
    "# 14. SUMMARY OF FEATURES CREATED\n",
    "print(\"\\nFEATURE ENGINEERING SUMMARY\\n\")\n",
    "\n",
    "new_features = set(df_final_clean.columns) - set(df.columns)\n",
    "print(f\"Total new features created: {len(new_features)}\")\n",
    "print(\"Feature categories:\")\n",
    "print(\"  - Price-based features: ~30\")\n",
    "print(\"  - Consumption features: 7\")\n",
    "print(\"  - Margin features: 6\")\n",
    "print(\"  - Temporal features: 16\")\n",
    "print(\"  - Channel/Origin features: 6\")\n",
    "print(\"  - Product/Service features: 8\")\n",
    "print(\"  - Interaction features: 7\")\n",
    "print(\"  - Statistical features: 6\")\n",
    "print(f\"Total columns in final dataset: {df_final_clean.shape[1]}\")\n",
    "print(f\"Total rows: {df_final_clean.shape[0]}\")\n",
    "\n",
    "sample_new_features = list(new_features)[:10]\n",
    "print(df_final_clean[sample_new_features].head())\n",
    "\n",
    "print(\"\\nFEATURE ENGINEERING COMPLETE!\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
